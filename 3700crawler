#!/usr/bin/env python3

import argparse
import socket
import ssl
from urllib.parse import urlparse
from html.parser import HTMLParser

DEFAULT_SERVER = "www.3700.network"
DEFAULT_PORT = 443
CRLF = "\r\n\r\n"
LOGIN_URL = "https://www.3700.network/accounts/login/?next=/fakebook/"
pages_visited = {}
pages_to_visit = []
secret_flags = []

# HTMLParser that looks for links with /fakebook/ and also for secret flags
class LinkParser(HTMLParser):
    def __init__(self):
        super().__init__()
        self.pages_to_visit = []

    def handle_starttag(self, tag, attrs):
        global pages_visited
        if tag == 'a':
            for attr, value in attrs:
                if attr == 'href' and value is not None and '/fakebook/' in value:
                    if value not in pages_visited:
                        return self.pages_to_visit.append(value)

    def handle_data(self, data):
        global global_secret_flags
        if "FLAG:" in data:
            secret_flag = data.split(": ")[1]
            if secret_flag not in secret_flags:
                secret_flags.append(secret_flag)

# HTMLParser that looks for the csrfmiddlewaretoken used to log in
class InputParser(HTMLParser):
    csrfmiddlewaretoken_value = ""

    def handle_starttag(self, tag, attrs):
        if tag == 'input':
            for attr, value in attrs:
                if attr == 'name' and value == 'csrfmiddlewaretoken':
                    for attr, value in attrs:
                        if attr == 'value':
                            self.csrfmiddlewaretoken_value = value
                            return 

class Crawler:
    def __init__(self, args):
        self.server = args.server
        self.port = args.port
        self.username = args.username
        self.password = args.password
        self.csrf_token = None
        self.session_id = None
        self.socket = self.create_socket() # create one socket that will remain open

    def create_socket(self):
        # TLS wrapper
        context = ssl.create_default_context()
        mysocket = context.wrap_socket(socket.socket(socket.AF_INET), server_hostname=self.server)
        mysocket.connect((self.server, self.port))

        cert = mysocket.getpeercert()

        return mysocket

    # receives response based on the content_length header
    def receive_response(self, socket):
        response = b""
        while True:
            chunk = socket.recv(4096)
            if not chunk:
                break
            response += chunk

            # check if end of headers reached
            if b"\r\n\r\n" in response:
                headers_end_index = response.find(b"\r\n\r\n")
                headers = response[:headers_end_index].decode('ascii')
                content_length = self.get_content_length(headers)
                if content_length is not None:
                    # check if all content has been received
                    if len(response) - headers_end_index - len(CRLF) >= content_length:
                        break
                else:
                    # if content-length header is not present, assume end of response
                    break

        return response

    # find content-length header
    def get_content_length(self, response):
        content_length_str = "content-length: "
        start_index = response.find(content_length_str)
        if start_index != -1:
            end_index = response.find("\r\n", start_index)
            if end_index != -1:
                content_length_value = response[start_index + len(content_length_str):end_index]
                try:
                    return int(content_length_value)
                except ValueError:
                    return None
        return None

    # retrieve just the HTML content after the headers
    def getHTMLContent(self, data):
        html_start_index = data.find(CRLF) + len(CRLF)
        html_content = data[html_start_index:]
        return html_content

    # login to Fakebook
    def login(self):
        global pages_to_visit

        logged_in = False
        while not logged_in:
            # send get request to the fakebook login page
            login_data = self.GET(LOGIN_URL)
            login_data_status_code, parsedLoginData = self.parseResponse(login_data)

            # print(f'GET RESPONSE LOGIN: {login_data}')
            # print(f'parsedLoginData: {parsedLoginData}')

            if login_data_status_code == str(200):
                logged_in = True

        # update csrf_token and session_id
        self.csrf_token = parsedLoginData['set-cookie']['csrftoken']
        self.session_id = parsedLoginData['set-cookie']['sessionid']
        
        # use input parser to parse the html content of the login page and retreive csrfmiddlewaretoken
        login_data_html = self.getHTMLContent(login_data)
        # print(f"HTML CONTENT: {login_data_html}")
        input_parser = InputParser()
        input_parser.feed(login_data_html)
        csrf_token = input_parser.csrfmiddlewaretoken_value

        # create the body of the post request
        postBody = f"username={self.username}&password={self.password}&csrfmiddlewaretoken={csrf_token}&next=/fakebook/"
        login_successful = False
        while not login_successful:
            # send post request
            post_login_data = self.POST(LOGIN_URL, postBody, parsedLoginData['cookie-string'])
            # print(f"POST LOGIN RESPONSE: {post_login_data}")
            post_login_status_code, parsed_post_login_data = self.parseResponse(post_login_data)
            # print(f"parsed_post_login_data: {parsed_post_login_data}")

            # received redirect status code
            if post_login_status_code == str(302):
                login_successful = True
                # print(f'Received Status Code: {post_login_status_code}')


        # update csrf_token and session_id post-login
        self.csrf_token = parsed_post_login_data['set-cookie']['csrftoken']
        self.session_id = parsed_post_login_data['set-cookie']['sessionid']

        # create redirect url and send another GET request
        redirect_url = parsed_post_login_data['location']
        # print(f"REDIRECT URL: {redirect_url}")
        homePageData = self.GET("/fakebook/")
        
        return homePageData
        


    def GET(self, url):
        url = urlparse(url)
        path = url.path

        cookieString = self.createCookieString()
        request = f"GET {path} HTTP/1.1\nHost: {self.server}\nCookie: {cookieString}\nConnection: keep-alive{CRLF}"

        # print("Request to %s:%d" % (self.server, self.port))
        # print(request)

        # check if server closed socket and re-initiate socket connection
        try:
            self.socket.send(request.encode('ascii'))
        except:
            # print("ERROR: Socket connection closed. Reopening connection.")
            self.socket.close()

            self.socket = context.wrap_socket(socket.socket(socket.AF_INET), server_hostname=self.server)
            self.socket.connect((self.server, self.port))
            # resend request
            self.socket.send(request.encode('ascii'))
            # receive response again
            data = self.receive_response(self.socket).decode('ascii')

        data = self.receive_response(self.socket).decode('ascii')

        return data

    def POST(self, url, data, cookies):
        url = urlparse(url)
        path = url.path

        content_length = len(data)

        cookie_string = f"csrftoken={self.csrf_token}; sessionid={self.session_id}"
        request = f"POST {path} HTTP/1.1\r\nHost: {self.server}\r\nConnection: keep-alive\r\n" \
                            f"Content-Length: {content_length}\r\n" \
                            f"Content-Type: application/x-www-form-urlencoded\r\n" \
                            f"Cookie: {cookie_string}{CRLF}" \
                            f"{data}\r\n"

        # print("Request to %s:%d" % (self.server, self.port))
        # print(request)
        try:
            self.socket.send(request.encode('ascii'))
        except:
            # print("ERROR: Socket connection closed. Reopening connection.")
            self.socket.close()

            self.socket = context.wrap_socket(socket.socket(socket.AF_INET), server_hostname=self.server)
            self.socket.connect((self.server, self.port))
            # Resend the request
            self.socket.send(request.encode('ascii'))
            # Receive the response again
            data = self.receive_response(self.socket).decode('ascii')
            # create a new socket and resent

        data = self.receive_response(self.socket).decode('ascii')

        return data
    
    # configures the cookie string to send in requests
    def createCookieString(self):
        cookieString = ""
        if self.csrf_token:
            if self.session_id:
                cookieString = f"csrftoken={self.csrf_token}; sessionid={self.session_id}"
            else:
                cookieString = f"csrftoken={self.csrf_token}"
        elif self.session_id:
            cookieString = f"sessionid={self.session_id}"
        return cookieString

    # reformats the cookies from the parsedData
    def formatCookies(self, parsedData):
        if 'set-cookie' not in parsedData.keys():
            return parsedData
        
        cookieString = ""
        if 'csrftoken' in parsedData['set-cookie'].keys():
            if 'sessionid' in parsedData['set-cookie'].keys():
                cookieString = f"csrftoken={parsedData['set-cookie']['csrftoken']}; sessionid={parsedData['set-cookie']['sessionid']}"
            else:
                cookieString = f"csrftoken={parsedData['set-cookie']['csrftoken']}"
        elif 'sessionid' in parsedData['set-cookie'].keys():
            cookieString = f"sessionid={parsedData['set-cookie']['sessionid']}"

        parsedData['cookie-string'] = cookieString
        return parsedData

    def parseResponse(self, data):
        # Get the end index of the header section before the body begins
        headers_end_index = data.find(CRLF)

        # retrive the status_line to get the status code
        status_line = data[:headers_end_index].split('\r\n')[0]
        status_code = status_line.split(' ')[1]

        # retrieve headers
        headers = data[:headers_end_index].split('\r\n')[1:]

        # retrieve the body
        body = data[headers_end_index:]

        # create dictionary for the parsed data
        parsedData = {}
        parsedData['body'] = body

        for header in headers:
            # splitting the csrftoken and sessionid
            if header.startswith('set-cookie:'):
                parts = header.split(': ')
                cookie_key, cookie_value = parts[0], parts[1]

                cookie_parts = cookie_value.split('; ')
                key = cookie_parts[0].split('=')[0]
                value = cookie_parts[0].split('=')[1]

                parsedData.setdefault('set-cookie', {})[key] = value
            # else the rest are just normal headers
            else:
                key, value = header.split(': ', 1)
                parsedData[key.lower()] = value
        # print(f'PARSED DATA: {parsedData}')

        return status_code, self.formatCookies(parsedData)

    def run(self):
        global secret_flags
        pages_to_visit = set()
        visited_pages = set()
        parser = LinkParser()

        # send initial request to root url
        request = f"GET / HTTP/1.0\r\nHost: {self.server}\r\n\r\n"

        root_data = self.GET('/')
        root_data_status_code, parsed_root_data = self.parseResponse(root_data)

        # login and get the home page data
        home_page_data = self.login()

        visited_pages.add('/fakebook/')

        home_page_status_code, parsed_home_page_data = self.parseResponse(home_page_data)

        home_page_html = self.getHTMLContent(home_page_data)

        # feed the home page html to our parser and retrieve the links on that page to begin traversing
        parser.feed(home_page_html)
        links = parser.pages_to_visit
        
        # add link to our local pages_to_visit
        for link in links: 
            if link not in visited_pages and link not in pages_to_visit:
                pages_to_visit.add(link)

        # continue looping while there are pages to traverse
        while len(pages_to_visit) > 0:
            # print(f"SECRET FLAGS: {secret_flags}")
            # print(f"Remaining pages: {len(pages_to_visit)}")

            next_url = pages_to_visit.pop()

            try:
                next_url_data = self.GET(next_url)
                next_url_status_code, parsed_next_url_data = self.parseResponse(next_url_data)
                
                # add the next_url to our set of visited_pages
                visited_pages.add(next_url)

                # success
                if next_url_status_code == str(200):
                    html = self.getHTMLContent(next_url_data)
                    parser.feed(html)

                    links = parser.pages_to_visit
                    
                    for link in links:
                        if link not in visited_pages and link not in pages_to_visit:
                            pages_to_visit.add(link)

                    # secret_flags.extend(parser.secret_flags)

                    # if 5 secret_flags are found then print flags, return and exit program
                    if len(secret_flags) == 5:
                        for secret_flag in secret_flags:
                            print(secret_flag)
                        return secret_flags
                # redirect
                elif next_url_status_code == str(301) or next_url_status_code == str(302):
                    self.pages_to_visit.append(parse_next_url['location'].replace(self.server, ""))
                # abandon
                elif next_url_status_code == str(403) or next_url_status_code == str(404) or next_url_status_code == str(400):
                    pass
                # revisit again
                elif next_url_status_code == str(503):
                    pages_to_visit.add(next_url)
                else: 
                    raise Exception(f"Error: Unrecognized status - {next_url_status_code}")
            except socket.timeout:
                raise Exception(f"Error: Socket timeout.")

        for secret_flag in secret_flags:
            print(secret_flag)
        return secret_flags


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description='crawl Fakebook')
    parser.add_argument('-s', dest="server", type=str, default=DEFAULT_SERVER, help="The server to crawl")
    parser.add_argument('-p', dest="port", type=int, default=DEFAULT_PORT, help="The port to use")
    parser.add_argument('username', type=str, help="The username to use")
    parser.add_argument('password', type=str, help="The password to use")
    args = parser.parse_args()
    sender = Crawler(args)
    sender.run()